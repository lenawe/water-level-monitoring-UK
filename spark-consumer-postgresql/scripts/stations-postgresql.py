from pyspark.sql import SparkSession
spark = SparkSession \
    .builder \
    .appName("Streaming pipeline to PostgreSQL") \
    .master("local[*]") \
    .config("spark.driver.host", "localhost")\
    .getOrCreate()

spark.sparkContext.setLogLevel("ERROR")

def get_input_df(topic):
  return spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:9092") \
    .option("subscribe", topic) \
    .option("startingOffsets", "earliest") \
    .load()
